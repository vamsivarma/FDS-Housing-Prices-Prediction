{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning Algorithms.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOPN9sGyN/rEthkSVoHSq8e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vamsivarma/FDS-Housing-Prices-Prediction/blob/master/Machine_Learning_Algorithms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTXWRo2ACiD6",
        "colab_type": "text"
      },
      "source": [
        "# Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUcxOeuPm_JU",
        "colab_type": "code",
        "outputId": "971bb1d2-b9c0-4021-d409-cf6e8746e277",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "'''\n",
        "The following code is for the Linear Regression\n",
        "Created by- ANALYTICS VIDHYA\n",
        "'''\n",
        "\n",
        "# importing required libraries\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# read the train and test dataset\n",
        "train_data = pd.read_csv('https://raw.githubusercontent.com/vamsivarma/datasets/master/machine_learning/linear_regression/train.csv')\n",
        "test_data = pd.read_csv('https://raw.githubusercontent.com/vamsivarma/datasets/master/machine_learning/linear_regression/test.csv')\n",
        "\n",
        "print(train_data.head())\n",
        "\n",
        "# shape of the dataset\n",
        "print('\\nShape of training data :',train_data.shape)\n",
        "print('\\nShape of testing data :',test_data.shape)\n",
        "\n",
        "# Now, we need to predict the missing target variable in the test data\n",
        "# target variable - Item_Outlet_Sales\n",
        "\n",
        "# seperate the independent and target variable on training data\n",
        "train_x = train_data.drop(columns=['Item_Outlet_Sales'],axis=1)\n",
        "train_y = train_data['Item_Outlet_Sales']\n",
        "\n",
        "# seperate the independent and target variable on training data\n",
        "test_x = test_data.drop(columns=['Item_Outlet_Sales'],axis=1)\n",
        "test_y = test_data['Item_Outlet_Sales']\n",
        "\n",
        "'''\n",
        "Create the object of the Linear Regression model\n",
        "You can also add other parameters and test your code here\n",
        "Some parameters are : fit_intercept and normalize\n",
        "Documentation of sklearn LinearRegression: \n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
        "\n",
        " '''\n",
        "model = LinearRegression()\n",
        "\n",
        "# fit the model with the training data\n",
        "model.fit(train_x,train_y)\n",
        "\n",
        "# coefficeints of the trained model\n",
        "print('\\nCoefficient of model :', model.coef_)\n",
        "\n",
        "# intercept of the model\n",
        "print('\\nIntercept of model',model.intercept_)\n",
        "\n",
        "# predict the target on the test dataset\n",
        "predict_train = model.predict(train_x)\n",
        "print('\\nItem_Outlet_Sales on training data',predict_train) \n",
        "\n",
        "# Root Mean Squared Error on training dataset\n",
        "rmse_train = mean_squared_error(train_y,predict_train)**(0.5)\n",
        "print('\\nRMSE on train dataset : ', rmse_train)\n",
        "\n",
        "# predict the target on the testing dataset\n",
        "predict_test = model.predict(test_x)\n",
        "print('\\nItem_Outlet_Sales on test data',predict_test) \n",
        "\n",
        "# Root Mean Squared Error on testing dataset\n",
        "rmse_test = mean_squared_error(test_y,predict_test)**(0.5)\n",
        "print('\\nRMSE on test dataset : ', rmse_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Item_Weight  ...  Outlet_Type_Supermarket Type3\n",
            "0     6.800000  ...                              0\n",
            "1    15.600000  ...                              0\n",
            "2    12.911575  ...                              1\n",
            "3    11.800000  ...                              0\n",
            "4    17.850000  ...                              0\n",
            "\n",
            "[5 rows x 36 columns]\n",
            "\n",
            "Shape of training data : (1364, 36)\n",
            "\n",
            "Shape of testing data : (341, 36)\n",
            "\n",
            "Coefficient of model : [-3.84197604e+00  9.83065945e+00  1.61711856e+01  6.09197622e+01\n",
            " -8.64161561e+01  1.23593376e+02  2.34714039e+02 -2.44597425e+02\n",
            " -2.72938329e+01 -8.09611456e+00 -3.01147840e+02  1.70727611e+02\n",
            " -5.40194744e+01  7.34248834e+01  1.70313375e+00 -5.07701615e+01\n",
            "  1.63553657e+02 -5.85286125e+01  1.04913492e+02 -6.01944874e+01\n",
            "  1.98948206e+02 -1.40959023e+02  1.19426257e+02  2.66382669e+01\n",
            " -1.85619792e+02  1.43925357e+03  2.16134663e+02  3.54723990e+01\n",
            "  3.54832996e+02 -5.54559635e+00 -3.49287400e+02 -1.39202954e+03\n",
            " -2.57982359e+02 -9.59016062e+02  2.60902796e+03]\n",
            "\n",
            "Intercept of model -121926.97473298332\n",
            "\n",
            "Item_Outlet_Sales on training data [ 803.88817641 1733.98835979 3294.52154482 ...  811.16967914 2343.96927185\n",
            " 2444.98869913]\n",
            "\n",
            "RMSE on train dataset :  1135.8159344155245\n",
            "\n",
            "Item_Outlet_Sales on test data [ 1615.37962439  3168.60806673  2564.31326686  2685.29698657\n",
            "  2771.82059109  4223.3788671   2615.10827403   565.8088248\n",
            "  4000.68496927  1035.54578573  2184.60316447  1033.54185437\n",
            "   150.22804639  1616.19932803  2370.37858454  1953.693325\n",
            "  2307.09514556  1429.85271583  2343.42149697  3780.28905363\n",
            "   583.44339124  1089.08346168  2323.64661483  3559.90832258\n",
            "  1829.46789667  1602.03985138   840.70282292  1823.14253132\n",
            "  3145.30906529  1823.30397678  2103.35401623  3025.02597477\n",
            "  2265.03907268   697.33936172  4474.05156681  2270.45195749\n",
            "  1897.45212218  3305.0110824   2228.36615412  3767.90052861\n",
            "  2162.33844917   665.40410258  -926.22966666   738.30407877\n",
            "   197.90808777  2483.25075805  3693.05388376  2458.43116228\n",
            "  1329.02544771   -57.67123156  1952.26612825  3614.4167807\n",
            "  2127.22359714  2486.1932574   1826.90446272   786.7283994\n",
            "  3200.67525412  1981.66000538  2326.98747373  3535.12951812\n",
            "    53.4756877    129.4629475   4259.8975191   3732.15225981\n",
            "  4454.54642228   717.26348394  1431.6614166    581.01605137\n",
            "  1119.93954645  2392.48117429  1155.07145201  3528.03281464\n",
            "  2044.86804694   455.24692632  1342.74411911  1033.2840843\n",
            "  1406.11005231   794.30323743  1098.87255812    83.75695654\n",
            "  1250.60074702  1495.67548794  2424.43083225  1844.12427139\n",
            "  3082.43684194  3765.07357641   771.99003119  4435.95849625\n",
            "   738.14937479   850.57494768  2622.28171329  1655.50682655\n",
            "   907.1351255   4290.06774145   953.43327412  5344.75965244\n",
            "  4088.62424173  2806.91278755  3128.8067004   1928.5781408\n",
            "  4036.11769697  3180.16424086  3139.20756065   542.83160506\n",
            "  2532.07785569  1105.76857669  3504.70144046  3939.48193634\n",
            "   333.08756699  1948.88080922  1231.78773626  2740.61520829\n",
            "  2346.30720313  3424.19140178  3051.02145123  1014.75408262\n",
            "  1782.52495649  1841.62002811  3947.82775657  1614.81023184\n",
            "  1389.86016917  1928.35682551  2619.4880638   2472.77585379\n",
            "  2692.29331855    78.62892708  2330.19059149  4159.73973081\n",
            "  4529.46230433  2264.57300155  1826.88342763  1275.25198009\n",
            "  -457.62680268   329.71458616  5805.46289307 -1450.16404187\n",
            "  1501.61687972  2965.88387942  1611.61916429  1886.73538613\n",
            "  1242.79778954  4296.14339619  1728.68334987  1509.00474116\n",
            "  2260.5918405   4159.20469494  3193.38759006  1509.53713972\n",
            "  2210.42073119  5754.97388686 -1170.50864902  3162.64617061\n",
            "  1994.01620756  1917.42431232  4404.60357762   997.35766781\n",
            "  1742.51236828  2265.77611998  2543.6189625   1469.66880224\n",
            "  1975.14690278  1225.30048856  4218.66518874  1697.85375137\n",
            "  2790.38688349  3935.99362435   625.06246143  2373.6866766\n",
            "  1831.0172668   1796.26777    -1075.85814761   427.15550704\n",
            "  1746.36375123   233.53413014  1774.33869755  2918.17108391\n",
            "  1912.23196062  3497.76791      605.64499947   761.50725234\n",
            "   575.95154528  2460.73367421  1613.43332209  1746.36921802\n",
            "  1366.92450243  2750.82093523  2708.27802108  2113.05123036\n",
            "  4091.83752837  2621.18104708  3834.85938706   866.33297998\n",
            "  3178.14854212  1320.60993899   614.11653153  2996.50726857\n",
            "  4183.21848289  2768.14376223  1894.7224403   2168.35936706\n",
            "  -430.75854506  1752.34512895  2547.47132497  3202.07672874\n",
            "  4158.43802333  2603.79263873  4096.2558171   4530.17698005\n",
            "  2657.59669754  1845.45481481  3390.50113508  2297.02310717\n",
            "  1935.22179911  1039.45233714  1610.06188742  2349.26388899\n",
            "  1687.75642234  1416.88045961  3186.47487698  1380.9005566\n",
            "  2048.98028877  3115.36727803  3192.74829239  2957.81471134\n",
            "  -309.39482285  3792.4834738   3808.61032694  3669.63236467\n",
            "  3736.43245566  2277.01639962   857.76812536  2528.67482118\n",
            "  4700.44879575  2872.01837914  2804.08508738 -1045.53520215\n",
            "  -183.90085944  2556.47193302  3194.77054019  3108.48089695\n",
            "  4718.52624333  3623.54852334  3038.4043458   2900.27886742\n",
            "  1042.6899685   3242.69016168  1632.6328344   3395.96081244\n",
            "  2213.18339089  2707.37203753  4165.66077486  1492.34822792\n",
            "  -132.72238794  1102.63092166  1438.80008104  1443.75837334\n",
            "  1829.01554695   973.12771481  3271.39421376  3254.27432253\n",
            "  -161.46169522    72.58218786  1774.24125644  -632.66831423\n",
            "  2531.55226268  4485.65882169  1796.44459658  2519.74607773\n",
            "  2371.38081459  4194.8355524   -771.30234698  1344.46736265\n",
            "  -967.33576066  1353.05300573  3265.73163044  2670.2925567\n",
            "  1613.75708737  3189.58746374  -810.85964358  2753.09992531\n",
            "  2178.28032441  2732.98784197  2110.04822199  2327.68963809\n",
            "  3870.64913841  2926.04570599  2779.15291241   636.25728977\n",
            "  1194.1928894   4778.71033823  3066.39089093  3328.54835279\n",
            "  4400.46098188  1894.895569    4290.01251609   572.99300136\n",
            "  2579.24830491  3349.60698124  2982.54911796  2674.56165895\n",
            "  3763.95229207  3884.58791149  3782.90713719  3939.12885079\n",
            "  3850.1735489   3870.01081561  3964.5331962   2908.96433528\n",
            "  1001.51593302   509.85548611  2026.75019074  5691.58192484\n",
            "  2105.74552915  1747.54922009  3110.61258139   115.7401617\n",
            "  5172.75086929  3338.73543581  4144.05762646   805.53285192\n",
            "  2331.40657555  3206.99378836   386.55122767  2938.94701141\n",
            "  1873.28577011  2144.49147042  3082.87955228  3870.29871722\n",
            "  1791.43594337  1069.11477182  3294.84134826  5603.61296774\n",
            "  1645.44477396   232.82442927  1181.13519601  3701.34493377\n",
            "  4099.97384712  2877.21991084  3519.04358701  1707.98351381\n",
            "   170.07605396]\n",
            "\n",
            "RMSE on test dataset :  1009.2517232209692\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCMG4xn2DYE2",
        "colab_type": "text"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPDL5lQtDfdg",
        "colab_type": "code",
        "outputId": "feb5dcaa-f5d1-4f98-fc65-be80c411bee3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "'''\n",
        "The following code is for Logistic Regression\n",
        "Created by - ANALYTICS VIDHYA\n",
        "'''\n",
        "\n",
        "# importing required libraries\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# read the train and test dataset\n",
        "train_data = pd.read_csv('https://raw.githubusercontent.com/vamsivarma/datasets/master/machine_learning/logistic_regression/train.csv')\n",
        "test_data = pd.read_csv('https://raw.githubusercontent.com/vamsivarma/datasets/master/machine_learning/logistic_regression/test.csv')\n",
        "\n",
        "\n",
        "print(train_data.head())\n",
        "\n",
        "# shape of the dataset\n",
        "print('Shape of training data :',train_data.shape)\n",
        "print('Shape of testing data :',test_data.shape)\n",
        "\n",
        "# Now, we need to predict the missing target variable in the test data\n",
        "# target variable - Survived\n",
        "\n",
        "# seperate the independent and target variable on training data\n",
        "train_x = train_data.drop(columns=['Survived'],axis=1)\n",
        "train_y = train_data['Survived']\n",
        "\n",
        "# seperate the independent and target variable on testing data\n",
        "test_x = test_data.drop(columns=['Survived'],axis=1)\n",
        "test_y = test_data['Survived']\n",
        "\n",
        "'''\n",
        "Create the object of the Logistic Regression model\n",
        "You can also add other parameters and test your code here\n",
        "Some parameters are : fit_intercept and penalty\n",
        "Documentation of sklearn LogisticRegression: \n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "\n",
        " '''\n",
        "model = LogisticRegression()\n",
        "\n",
        "# fit the model with the training data\n",
        "model.fit(train_x,train_y)\n",
        "\n",
        "# coefficeints of the trained model\n",
        "print('Coefficient of model :', model.coef_)\n",
        "\n",
        "# intercept of the model\n",
        "print('Intercept of model',model.intercept_)\n",
        "\n",
        "# predict the target on the train dataset\n",
        "predict_train = model.predict(train_x)\n",
        "print('Target on train data',predict_train) \n",
        "\n",
        "# Accuray Score on train dataset\n",
        "accuracy_train = accuracy_score(train_y,predict_train)\n",
        "print('accuracy_score on train dataset : ', accuracy_train)\n",
        "\n",
        "# predict the target on the test dataset\n",
        "predict_test = model.predict(test_x)\n",
        "print('Target on test data',predict_test) \n",
        "\n",
        "# Accuracy Score on test dataset\n",
        "accuracy_test = accuracy_score(test_y,predict_test)\n",
        "print('accuracy_score on test dataset : ', accuracy_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Survived        Age     Fare  ...  Embarked_C  Embarked_Q  Embarked_S\n",
            "0         0  28.500000   7.2292  ...           1           0           0\n",
            "1         1  27.000000  10.5000  ...           0           0           1\n",
            "2         1  29.699118  16.1000  ...           0           0           1\n",
            "3         0  29.699118   0.0000  ...           0           0           1\n",
            "4         0  17.000000   8.6625  ...           0           0           1\n",
            "\n",
            "[5 rows x 25 columns]\n",
            "Shape of training data : (712, 25)\n",
            "Shape of testing data : (179, 25)\n",
            "Coefficient of model : [[-0.03112606  0.00155629  0.93299841  0.08451959 -1.02556785  1.24541941\n",
            "  -1.25346925  1.05047794  0.97898932  0.61562405 -1.14084292 -0.78091604\n",
            "  -0.28356149 -0.4478207   0.16173065  0.6339807  -0.04705229  0.20461808\n",
            "  -0.45766539 -0.33677639 -0.16688521  0.07948039  0.28573972 -0.37326995]]\n",
            "Intercept of model [0.07227482]\n",
            "Target on train data [0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1\n",
            " 1 0 0 0 1 0 1 1 1 1 0 0 0 1 0 0 1 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 1 0 0 1 0 0 0 1 1 0 0 1 1 0 1 0 0 0 0 1 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1\n",
            " 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 1 0\n",
            " 0 0 1 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
            " 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 1 0 1 0 1 1 0 0 0 1 1 0 1 0 0 1 1 1\n",
            " 0 0 1 0 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0\n",
            " 0 0 1 1 0 1 1 0 1 0 1 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1\n",
            " 1 0 0 1 1 0 1 1 0 0 0 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
            " 0 0 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 1 1 1 0 1 0 1 1 0 1\n",
            " 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0\n",
            " 0 1 0 0 0 0 0 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0\n",
            " 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1\n",
            " 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 1 0 1 1 1 0 0 1 1 0 1 1 0 0 0 0 1\n",
            " 0 1 0 1 1 0 0 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 0 0 1 1 0 1 0 0 1 1 0 1 1 0 0\n",
            " 1 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1\n",
            " 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 1 0 0 0\n",
            " 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0\n",
            " 1 0 1 1 1 0 1 0 0]\n",
            "accuracy_score on train dataset :  0.8047752808988764\n",
            "Target on test data [0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 1 0 1\n",
            " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
            " 1 0 0 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 1 1 1\n",
            " 0 1 0 0 0 0 1 1 1 1 0 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 1 0 1 0 0 0 0 0 0 0\n",
            " 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1]\n",
            "accuracy_score on test dataset :  0.8324022346368715\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftkORxecFMph",
        "colab_type": "text"
      },
      "source": [
        "# Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sWoHGzbFNTm",
        "colab_type": "code",
        "outputId": "de538f83-1be3-4b79-df75-06fb2e161ca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "'''\n",
        "The following code is for Decision Tree\n",
        "Created by - Analytics Vidhya\n",
        "'''\n",
        "\n",
        "# importing required libraries\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# read the train and test dataset\n",
        "train_data = pd.read_csv('https://raw.githubusercontent.com/vamsivarma/datasets/master/machine_learning/decision_tree/train.csv')\n",
        "test_data = pd.read_csv('https://raw.githubusercontent.com/vamsivarma/datasets/master/machine_learning/decision_tree/test.csv')\n",
        "\n",
        "# shape of the dataset\n",
        "print('Shape of training data :',train_data.shape)\n",
        "print('Shape of testing data :',test_data.shape)\n",
        "\n",
        "# Now, we need to predict the missing target variable in the test data\n",
        "# target variable - Survived\n",
        "\n",
        "# seperate the independent and target variable on training data\n",
        "train_x = train_data.drop(columns=['Survived'],axis=1)\n",
        "train_y = train_data['Survived']\n",
        "\n",
        "# seperate the independent and target variable on testing data\n",
        "test_x = test_data.drop(columns=['Survived'],axis=1)\n",
        "test_y = test_data['Survived']\n",
        "\n",
        "'''\n",
        "Create the object of the Decision Tree model\n",
        "You can also add other parameters and test your code here\n",
        "Some parameters are : max_depth and max_features\n",
        "Documentation of sklearn DecisionTreeClassifier: \n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
        "\n",
        " '''\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "# fit the model with the training data\n",
        "model.fit(train_x,train_y)\n",
        "\n",
        "# depth of the decision tree\n",
        "print('Depth of the Decision Tree :', model.get_depth())\n",
        "\n",
        "# predict the target on the train dataset\n",
        "predict_train = model.predict(train_x)\n",
        "print('Target on train data',predict_train) \n",
        "\n",
        "# Accuray Score on train dataset\n",
        "accuracy_train = accuracy_score(train_y,predict_train)\n",
        "print('accuracy_score on train dataset : ', accuracy_train)\n",
        "\n",
        "# predict the target on the test dataset\n",
        "predict_test = model.predict(test_x)\n",
        "print('Target on test data',predict_test) \n",
        "\n",
        "# Accuracy Score on test dataset\n",
        "accuracy_test = accuracy_score(test_y,predict_test)\n",
        "print('accuracy_score on test dataset : ', accuracy_test)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of training data : (712, 25)\n",
            "Shape of testing data : (179, 25)\n",
            "Depth of the Decision Tree : 19\n",
            "Target on train data [0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0\n",
            " 1 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0\n",
            " 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 1 1 1 0 0 0 0 0\n",
            " 0 0 0 0 1 0 0 1 0 1 0 1 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 1 1 0\n",
            " 0 0 0 1 1 0 0 1 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1\n",
            " 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 1 1 1 0 1 0 0 0 1 0\n",
            " 0 1 1 0 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0\n",
            " 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1\n",
            " 1 0 0 1 1 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
            " 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1\n",
            " 0 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 0 1 0 0\n",
            " 0 1 0 0 0 0 0 1 1 0 0 1 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0\n",
            " 0 0 1 1 1 0 0 1 0 1 1 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
            " 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 1\n",
            " 0 0 0 1 1 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 1 1 0 1 1 1 0\n",
            " 1 0 1 0 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1\n",
            " 0 0 0 1 0 1 1 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 0 1 0 1 0\n",
            " 1 0 0 0 1 0 0 1 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0\n",
            " 1 0 1 1 1 0 0 1 0]\n",
            "accuracy_score on train dataset :  0.9859550561797753\n",
            "Target on test data [0 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 1 1 0 1 0 1 1 0\n",
            " 1 0 0 0 1 0 0 0 1 1 0 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0\n",
            " 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1\n",
            " 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 1 1 0 0 0 0\n",
            " 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 1 1 0 1 0 0 0 0 0]\n",
            "accuracy_score on test dataset :  0.776536312849162\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDa_2Q54HBFi",
        "colab_type": "text"
      },
      "source": [
        "# SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8spONqJZHBS9",
        "colab_type": "code",
        "outputId": "4eb594b7-1ff4-49c1-f90e-1d333e4b9301",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "'''\n",
        "The following code is for Support Vector Machines\n",
        "Created by - ANALYTICS VIDHYA\n",
        "'''\n",
        "# importing required libraries\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# read the train and test dataset\n",
        "train_data = pd.read_csv('https://raw.githubusercontent.com/vamsivarma/datasets/master/machine_learning/svm/train.csv')\n",
        "test_data = pd.read_csv('https://raw.githubusercontent.com/vamsivarma/datasets/master/machine_learning/svm/test.csv')\n",
        "\n",
        "# shape of the dataset\n",
        "print('Shape of training data :',train_data.shape)\n",
        "print('Shape of testing data :',test_data.shape)\n",
        "\n",
        "# Now, we need to predict the missing target variable in the test data\n",
        "# target variable - Survived\n",
        "\n",
        "# seperate the independent and target variable on training data\n",
        "train_x = train_data.drop(columns=['Survived'],axis=1)\n",
        "train_y = train_data['Survived']\n",
        "\n",
        "# seperate the independent and target variable on testing data\n",
        "test_x = test_data.drop(columns=['Survived'],axis=1)\n",
        "test_y = test_data['Survived']\n",
        "\n",
        "'''\n",
        "Create the object of the Support Vector Classifier model\n",
        "You can also add other parameters and test your code here\n",
        "Some parameters are : kernal and degree\n",
        "Documentation of sklearn Support Vector Classifier: \n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
        "\n",
        " '''\n",
        "model = SVC()\n",
        "\n",
        "# fit the model with the training data\n",
        "model.fit(train_x,train_y)\n",
        "\n",
        "# predict the target on the train dataset\n",
        "predict_train = model.predict(train_x)\n",
        "print('Target on train data',predict_train) \n",
        "\n",
        "# Accuray Score on train dataset\n",
        "accuracy_train = accuracy_score(train_y,predict_train)\n",
        "print('accuracy_score on train dataset : ', accuracy_train)\n",
        "\n",
        "# predict the target on the test dataset\n",
        "predict_test = model.predict(test_x)\n",
        "print('Target on test data',predict_test) \n",
        "\n",
        "# Accuracy Score on test dataset\n",
        "accuracy_test = accuracy_score(test_y,predict_test)\n",
        "print('accuracy_score on test dataset : ', accuracy_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of training data : (712, 25)\n",
            "Shape of testing data : (179, 25)\n",
            "Target on train data [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0\n",
            " 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0\n",
            " 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0\n",
            " 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1\n",
            " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0\n",
            " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
            " 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
            " 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
            " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1\n",
            " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
            " 1 0 0 0 1 0 1 0 0]\n",
            "accuracy_score on train dataset :  0.651685393258427\n",
            "Target on test data [0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
            " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
            " 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "accuracy_score on test dataset :  0.7262569832402235\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yzw8yo4jHBlh",
        "colab_type": "text"
      },
      "source": [
        "# K-Nearest Neighbours"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzKWMa_8HBzm",
        "colab_type": "code",
        "outputId": "db24f6ed-b9a1-46ed-917a-4d3b62ae7db0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "'''\n",
        "The following code is for the K-Nearest Neighbors\n",
        "Created by - ANALYTICS VIDHYA\n",
        "'''\n",
        "# importing required libraries\n",
        "import pandas as pd\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# read the train and test dataset\n",
        "train_data = pd.read_csv('https://raw.githubusercontent.com/vamsivarma/datasets/master/machine_learning/knn/train.csv')\n",
        "test_data = pd.read_csv('https://raw.githubusercontent.com/vamsivarma/datasets/master/machine_learning/knn/test.csv')\n",
        "\n",
        "# shape of the dataset\n",
        "print('Shape of training data :',train_data.shape)\n",
        "print('Shape of testing data :',test_data.shape)\n",
        "\n",
        "# Now, we need to predict the missing target variable in the test data\n",
        "# target variable - Survived\n",
        "\n",
        "# seperate the independent and target variable on training data\n",
        "train_x = train_data.drop(columns=['Survived'],axis=1)\n",
        "train_y = train_data['Survived']\n",
        "\n",
        "# seperate the independent and target variable on testing data\n",
        "test_x = test_data.drop(columns=['Survived'],axis=1)\n",
        "test_y = test_data['Survived']\n",
        "\n",
        "'''\n",
        "Create the object of the K-Nearest Neighbor model\n",
        "You can also add other parameters and test your code here\n",
        "Some parameters are : n_neighbors, leaf_size\n",
        "Documentation of sklearn K-Neighbors Classifier: \n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
        "\n",
        " '''\n",
        "model = KNeighborsClassifier()  \n",
        "\n",
        "# fit the model with the training data\n",
        "model.fit(train_x,train_y)\n",
        "\n",
        "# Number of Neighbors used to predict the target\n",
        "print('\\nThe number of neighbors used to predict the target : ',model.n_neighbors)\n",
        "\n",
        "# predict the target on the train dataset\n",
        "predict_train = model.predict(train_x)\n",
        "print('\\nTarget on train data',predict_train) \n",
        "\n",
        "# Accuray Score on train dataset\n",
        "accuracy_train = accuracy_score(train_y,predict_train)\n",
        "print('accuracy_score on train dataset : ', accuracy_train)\n",
        "\n",
        "# predict the target on the test dataset\n",
        "predict_test = model.predict(test_x)\n",
        "print('Target on test data',predict_test) \n",
        "\n",
        "# Accuracy Score on test dataset\n",
        "accuracy_test = accuracy_score(test_y,predict_test)\n",
        "print('accuracy_score on test dataset : ', accuracy_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of training data : (712, 25)\n",
            "Shape of testing data : (179, 25)\n",
            "\n",
            "The number of neighbors used to predict the target :  5\n",
            "\n",
            "Target on train data [0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0\n",
            " 1 0 0 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 0\n",
            " 0 1 1 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0\n",
            " 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 1 0 1 0 0 0 1 0 0 0 1 0 0\n",
            " 0 0 0 1 1 0 0 1 0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
            " 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 1 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
            " 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0\n",
            " 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0\n",
            " 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 0 0 0 1 1 0 1 0 0 1\n",
            " 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 1 0 1 0\n",
            " 0 0 0 1 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 0 1 1 1 1 0 0 1 1 0 1 0 1 0 1 1 1 1\n",
            " 0 1 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0\n",
            " 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0\n",
            " 0 0 0 1 1 0 0 0 0 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1\n",
            " 1 0 0 0 0 1 0 0 0 1 1 0 0 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 1 1 1 0 1 0 0 0\n",
            " 0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 1 1 1 0 1 1 1 0\n",
            " 1 0 0 0 0 1 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 1\n",
            " 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 0 0 0\n",
            " 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 1 1 0 0 0 1 0 1 0 0 1 1 0 0 0 1 0 0 1 0 1 0\n",
            " 1 0 1 1 1 0 0 1 0]\n",
            "accuracy_score on train dataset :  0.8047752808988764\n",
            "Target on test data [0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0\n",
            " 1 0 0 1 1 0 0 0 1 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0\n",
            " 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 1 1 0 1 1 0 0 1 0 0 1\n",
            " 0 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 0 0\n",
            " 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0]\n",
            "accuracy_score on test dataset :  0.7150837988826816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ucJBPuHHCC-",
        "colab_type": "text"
      },
      "source": [
        "# K-means"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxzbOEGJHCQq",
        "colab_type": "code",
        "outputId": "e68e8612-628d-416b-d4ad-51543471ff04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "'''\n",
        "The following code is for the K-Means\n",
        "Created by - ANALYTICS VIDHYA\n",
        "'''\n",
        "\n",
        "# importing required libraries\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# read the train and test dataset\n",
        "train_data = pd.read_csv('https://raw.githubusercontent.com/vamsivarma/datasets/master/machine_learning/kmeans/train.csv')\n",
        "test_data = pd.read_csv('https://raw.githubusercontent.com/vamsivarma/datasets/master/machine_learning/kmeans/test.csv')\n",
        "\n",
        "# shape of the dataset\n",
        "print('Shape of training data :',train_data.shape)\n",
        "print('Shape of testing data :',test_data.shape)\n",
        "\n",
        "# Now, we need to divide the training data into differernt clusters\n",
        "# and predict in which cluster a particular data point belongs.  \n",
        "\n",
        "'''\n",
        "Create the object of the K-Means model\n",
        "You can also add other parameters and test your code here\n",
        "Some parameters are : n_clusters and max_iter\n",
        "Documentation of sklearn KMeans: \n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
        " '''\n",
        "\n",
        "model = KMeans()  \n",
        "\n",
        "# fit the model with the training data\n",
        "model.fit(train_data)\n",
        "\n",
        "# Number of Clusters\n",
        "print('\\nDefault number of Clusters : ',model.n_clusters)\n",
        "\n",
        "# predict the clusters on the train dataset\n",
        "predict_train = model.predict(train_data)\n",
        "print('\\nCLusters on train data',predict_train) \n",
        "\n",
        "# predict the target on the test dataset\n",
        "predict_test = model.predict(test_data)\n",
        "print('Clusters on test data',predict_test) \n",
        "\n",
        "# Now, we will train a model with n_cluster = 3\n",
        "model_n3 = KMeans(n_clusters=3)\n",
        "\n",
        "# fit the model with the training data\n",
        "model_n3.fit(train_data)\n",
        "\n",
        "# Number of Clusters\n",
        "print('\\nNumber of Clusters : ',model_n3.n_clusters)\n",
        "\n",
        "# predict the clusters on the train dataset\n",
        "predict_train_3 = model_n3.predict(train_data)\n",
        "print('\\nCLusters on train data',predict_train_3) \n",
        "\n",
        "# predict the target on the test dataset\n",
        "predict_test_3 = model_n3.predict(test_data)\n",
        "print('Clusters on test data',predict_test_3) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of training data : (100, 5)\n",
            "Shape of testing data : (100, 5)\n",
            "\n",
            "Default number of Clusters :  8\n",
            "\n",
            "CLusters on train data [3 4 7 4 3 1 1 4 4 5 0 0 5 7 4 0 7 2 1 3 2 5 5 7 2 6 0 0 6 5 2 5 5 6 6 0 2\n",
            " 0 2 5 7 2 0 0 7 5 5 7 4 0 5 7 1 0 6 0 1 2 3 2 5 3 1 6 5 6 2 5 5 0 1 0 3 1\n",
            " 4 4 3 5 1 5 1 5 0 1 2 1 7 5 2 5 2 4 0 6 0 1 5 3 0 3]\n",
            "Clusters on test data [5 3 2 7 1 3 6 5 1 2 5 2 1 1 1 5 5 1 1 4 6 6 1 1 5 1 6 3 1 6 0 3 5 1 3 7 0\n",
            " 4 5 7 7 3 2 6 1 5 1 4 5 5 2 3 5 0 3 5 0 5 5 1 5 5 1 0 4 1 0 1 5 5 1 2 7 0\n",
            " 1 6 5 7 5 3 5 1 2 6 1 3 5 1 3 7 3 2 5 1 7 3 3 3 0 7]\n",
            "\n",
            "Number of Clusters :  3\n",
            "\n",
            "CLusters on train data [2 1 0 1 2 0 2 1 1 2 1 1 2 0 1 1 0 2 2 2 2 2 2 0 2 0 1 1 0 2 2 2 2 0 0 1 2\n",
            " 1 2 2 0 2 1 1 0 2 2 0 1 1 2 0 2 1 0 1 2 2 2 2 2 2 2 0 2 0 2 2 2 1 0 1 2 2\n",
            " 1 1 1 2 1 2 2 2 1 2 2 2 0 2 2 2 2 1 1 0 1 2 2 2 1 2]\n",
            "Clusters on test data [2 2 2 0 2 2 0 2 2 2 2 2 2 0 0 2 2 2 2 1 0 0 2 2 2 2 0 2 2 0 1 2 2 2 2 0 1\n",
            " 1 2 0 0 2 2 0 2 2 2 1 2 2 2 2 2 1 2 2 1 2 2 2 2 2 2 1 1 2 1 2 2 2 1 2 0 1\n",
            " 2 0 2 0 2 1 2 2 2 0 2 2 2 2 2 0 2 2 2 2 0 2 2 2 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9QKdSnjHCcf",
        "colab_type": "text"
      },
      "source": [
        "# Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iBLoY0ZHCpt",
        "colab_type": "code",
        "outputId": "ed358f5c-2450-4a0d-b95e-b8cab7e4b6a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "'''\n",
        "The following code is for Naive Bayes\n",
        "Created by - ANALYTICS VIDHYA\n",
        "'''\n",
        "\n",
        "# importing required libraries\n",
        "import pandas as pd\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# read the train and test dataset\n",
        "train_data = pd.read_csv('https://raw.githubusercontent.com/vamsivarma/datasets/master/machine_learning/naive_bayes/train.csv')\n",
        "test_data = pd.read_csv('https://raw.githubusercontent.com/vamsivarma/datasets/master/machine_learning/naive_bayes/test.csv')\n",
        "\n",
        "# shape of the dataset\n",
        "print('Shape of training data :',train_data.shape)\n",
        "print('Shape of testing data :',test_data.shape)\n",
        "\n",
        "# Now, we need to predict the missing target variable in the test data\n",
        "# target variable - Survived\n",
        "\n",
        "# seperate the independent and target variable on training data\n",
        "train_x = train_data.drop(columns=['Survived'],axis=1)\n",
        "train_y = train_data['Survived']\n",
        "\n",
        "# seperate the independent and target variable on testing data\n",
        "test_x = test_data.drop(columns=['Survived'],axis=1)\n",
        "test_y = test_data['Survived']\n",
        "\n",
        "'''\n",
        "Create the object of the Naive Bayes model\n",
        "You can also add other parameters and test your code here\n",
        "Some parameters are : var_smoothing\n",
        "Documentation of sklearn GaussianNB: \n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\n",
        "\n",
        " '''\n",
        "model = GaussianNB()\n",
        "\n",
        "# fit the model with the training data\n",
        "model.fit(train_x,train_y)\n",
        "\n",
        "# predict the target on the train dataset\n",
        "predict_train = model.predict(train_x)\n",
        "print('Target on train data',predict_train) \n",
        "\n",
        "# Accuray Score on train dataset\n",
        "accuracy_train = accuracy_score(train_y,predict_train)\n",
        "print('accuracy_score on train dataset : ', accuracy_train)\n",
        "\n",
        "# predict the target on the test dataset\n",
        "predict_test = model.predict(test_x)\n",
        "print('Target on test data',predict_test) \n",
        "\n",
        "# Accuracy Score on test dataset\n",
        "accuracy_test = accuracy_score(test_y,predict_test)\n",
        "print('accuracy_score on test dataset : ', accuracy_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of training data : (712, 25)\n",
            "Shape of testing data : (179, 25)\n",
            "Target on train data [1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1\n",
            " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
            " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
            " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1]\n",
            "accuracy_score on train dataset :  0.44803370786516855\n",
            "Target on test data [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
            " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "accuracy_score on test dataset :  0.35195530726256985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y93LDXTrHC5W",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZS6UJ8oHDGN",
        "colab_type": "code",
        "outputId": "d7dce076-093b-4aab-8f68-c8de513bf3c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "'''\n",
        "The following code is for the Random Forest\n",
        "Created by - ANALYTICS VIDHYA\n",
        "'''\n",
        "\n",
        "# importing required libraries\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# read the train and test dataset\n",
        "train_data = pd.read_csv('https://raw.githubusercontent.com/vamsivarma/datasets/master/machine_learning/random_forest/train.csv')\n",
        "test_data = pd.read_csv('https://raw.githubusercontent.com/vamsivarma/datasets/master/machine_learning/random_forest/test.csv')\n",
        "\n",
        "# view the top 3 rows of the dataset\n",
        "print(train_data.head(3))\n",
        "\n",
        "# shape of the dataset\n",
        "print('\\nShape of training data :',train_data.shape)\n",
        "print('\\nShape of testing data :',test_data.shape)\n",
        "\n",
        "# Now, we need to predict the missing target variable in the test data\n",
        "# target variable - Survived\n",
        "\n",
        "# seperate the independent and target variable on training data\n",
        "train_x = train_data.drop(columns=['Survived'],axis=1)\n",
        "train_y = train_data['Survived']\n",
        "\n",
        "# seperate the independent and target variable on testing data\n",
        "test_x = test_data.drop(columns=['Survived'],axis=1)\n",
        "test_y = test_data['Survived']\n",
        "\n",
        "'''\n",
        "\n",
        "Create the object of the Random Forest model\n",
        "You can also add other parameters and test your code here\n",
        "Some parameters are : n_estimators and max_depth\n",
        "Documentation of sklearn RandomForestClassifier: \n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
        "\n",
        "'''\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "# fit the model with the training data\n",
        "model.fit(train_x,train_y)\n",
        "\n",
        "# number of trees used\n",
        "print('Number of Trees used : ', model.n_estimators)\n",
        "\n",
        "# predict the target on the train dataset\n",
        "predict_train = model.predict(train_x)\n",
        "print('\\nTarget on train data',predict_train) \n",
        "\n",
        "# Accuray Score on train dataset\n",
        "accuracy_train = accuracy_score(train_y,predict_train)\n",
        "print('\\naccuracy_score on train dataset : ', accuracy_train)\n",
        "\n",
        "# predict the target on the test dataset\n",
        "predict_test = model.predict(test_x)\n",
        "print('\\nTarget on test data',predict_test) \n",
        "\n",
        "# Accuracy Score on test dataset\n",
        "accuracy_test = accuracy_score(test_y,predict_test)\n",
        "print('\\naccuracy_score on test dataset : ', accuracy_test)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Survived        Age     Fare  ...  Embarked_C  Embarked_Q  Embarked_S\n",
            "0         0  28.500000   7.2292  ...           1           0           0\n",
            "1         1  27.000000  10.5000  ...           0           0           1\n",
            "2         1  29.699118  16.1000  ...           0           0           1\n",
            "\n",
            "[3 rows x 25 columns]\n",
            "\n",
            "Shape of training data : (712, 25)\n",
            "\n",
            "Shape of testing data : (179, 25)\n",
            "Number of Trees used :  100\n",
            "\n",
            "Target on train data [0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0\n",
            " 1 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0\n",
            " 0 1 1 0 0 1 0 1 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 1 1 1 0 0 0 0 0\n",
            " 0 0 0 0 1 0 0 1 0 1 0 1 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 1 1 0\n",
            " 0 0 0 1 1 0 0 1 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1\n",
            " 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 1 1 1 0 1 0 0 0 1 0\n",
            " 0 1 1 0 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0\n",
            " 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1\n",
            " 1 0 0 1 1 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
            " 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1\n",
            " 0 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 0 1 0 0\n",
            " 0 1 0 0 0 0 0 1 1 0 0 1 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0\n",
            " 0 0 1 1 1 0 0 1 0 1 1 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
            " 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 1\n",
            " 0 0 0 1 1 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 1 1 0 1 1 1 0\n",
            " 1 0 1 0 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1\n",
            " 0 0 0 1 0 1 1 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 0 1 0 1 0\n",
            " 1 0 0 0 1 0 0 1 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0\n",
            " 1 0 1 1 1 0 0 1 0]\n",
            "\n",
            "accuracy_score on train dataset :  0.9859550561797753\n",
            "\n",
            "Target on test data [0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 1 0 1 0 1 1 0\n",
            " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0\n",
            " 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 1 0 1 1 0 0 1 0 0 0 0 1 1 1 0 1 1 0 1\n",
            " 0 1 0 0 0 0 1 1 1 1 0 1 1 0 1 1 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 0 0\n",
            " 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0]\n",
            "\n",
            "accuracy_score on test dataset :  0.8268156424581006\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWfvHbriHDTr",
        "colab_type": "text"
      },
      "source": [
        "# PCA (Principle Component Analysis)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5Rp0vDAHDhw",
        "colab_type": "code",
        "outputId": "83721c44-3662-46f3-f5d8-bb56cc17562f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "'''\n",
        "The following code is for Principal Component Analysis (PCA)\n",
        "Created by - ANALYTICS VIDHYA\n",
        "'''\n",
        "# importing required libraries\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error  \n",
        "\n",
        "# read the train and test dataset\n",
        "train_data = pd.read_csv('https://raw.githubusercontent.com/vamsivarma/datasets/master/machine_learning/pca/train.csv')\n",
        "test_data = pd.read_csv('https://raw.githubusercontent.com/vamsivarma/datasets/master/machine_learning/pca/test.csv')\n",
        "\n",
        "\n",
        "# view the top 3 rows of the dataset\n",
        "print(train_data.head(3))\n",
        "\n",
        "# shape of the dataset\n",
        "print('\\nShape of training data :',train_data.shape)\n",
        "print('\\nShape of testing data :',test_data.shape)\n",
        "\n",
        "# Now, we need to predict the missing target variable in the test data\n",
        "# target variable - Survived\n",
        "\n",
        "# seperate the independent and target variable on training data\n",
        "# target variable - Item_Outlet_Sales\n",
        "train_x = train_data.drop(columns=['Item_Outlet_Sales'],axis=1)\n",
        "train_y = train_data['Item_Outlet_Sales']\n",
        "\n",
        "# seperate the independent and target variable on testing data\n",
        "test_x = test_data.drop(columns=['Item_Outlet_Sales'],axis=1)\n",
        "test_y = test_data['Item_Outlet_Sales']\n",
        "\n",
        "print('\\nTraining model with {} dimensions.'.format(train_x.shape[1]))\n",
        "\n",
        "# create object of model\n",
        "model = LinearRegression()\n",
        "\n",
        "# fit the model with the training data\n",
        "model.fit(train_x,train_y)\n",
        "\n",
        "# predict the target on the train dataset\n",
        "predict_train = model.predict(train_x)\n",
        "\n",
        "# Accuray Score on train dataset\n",
        "rmse_train = mean_squared_error(train_y,predict_train)**(0.5)\n",
        "print('\\nRMSE on train dataset : ', rmse_train)\n",
        "\n",
        "# predict the target on the test dataset\n",
        "predict_test = model.predict(test_x)\n",
        "\n",
        "# Accuracy Score on test dataset\n",
        "rmse_test = mean_squared_error(test_y,predict_test)**(0.5)\n",
        "print('\\nRMSE on test dataset : ', rmse_test)\n",
        "\n",
        "# create the object of the PCA (Principal Component Analysis) model\n",
        "# reduce the dimensions of the data to 12\n",
        "'''\n",
        "You can also add other parameters and test your code here\n",
        "Some parameters are : svd_solver, iterated_power\n",
        "Documentation of sklearn PCA:\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
        "'''\n",
        "model_pca = PCA(n_components=12)\n",
        "\n",
        "new_train = model_pca.fit_transform(train_x)\n",
        "new_test  = model_pca.fit_transform(test_x)\n",
        "\n",
        "print('\\nTraining model with {} dimensions.'.format(new_train.shape[1]))\n",
        "\n",
        "# create object of model\n",
        "model_new = LinearRegression()\n",
        "\n",
        "# fit the model with the training data\n",
        "model_new.fit(new_train,train_y)\n",
        "\n",
        "# predict the target on the new train dataset\n",
        "predict_train_pca = model_new.predict(new_train)\n",
        "\n",
        "# Accuray Score on train dataset\n",
        "rmse_train_pca = mean_squared_error(train_y,predict_train_pca)**(0.5)\n",
        "print('\\nRMSE on new train dataset : ', rmse_train_pca)\n",
        "\n",
        "# predict the target on the new test dataset\n",
        "predict_test_pca = model_new.predict(new_test)\n",
        "\n",
        "# Accuracy Score on test dataset\n",
        "rmse_test_pca = mean_squared_error(test_y,predict_test_pca)**(0.5)\n",
        "print('\\nRMSE on new test dataset : ', rmse_test_pca)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Item_Weight  ...  Outlet_Type_Supermarket Type3\n",
            "0     6.800000  ...                              0\n",
            "1    15.600000  ...                              0\n",
            "2    12.911575  ...                              1\n",
            "\n",
            "[3 rows x 36 columns]\n",
            "\n",
            "Shape of training data : (1364, 36)\n",
            "\n",
            "Shape of testing data : (341, 36)\n",
            "\n",
            "Training model with 35 dimensions.\n",
            "\n",
            "RMSE on train dataset :  1135.8159344155245\n",
            "\n",
            "RMSE on test dataset :  1009.2517232209692\n",
            "\n",
            "Training model with 12 dimensions.\n",
            "\n",
            "RMSE on new train dataset :  1159.9740391543316\n",
            "\n",
            "RMSE on new test dataset :  1014.4104988930773\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jC2od1tMHDuN",
        "colab_type": "text"
      },
      "source": [
        "# Gradient Boosting (GBM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToQ5qouSHD7N",
        "colab_type": "code",
        "outputId": "cece5e76-8720-4169-e16f-371836ca7e4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "'''\n",
        "The following code is for Gradient Boosting\n",
        "Created by - ANALYTICS VIDHYA\n",
        "'''\n",
        "\n",
        "# importing required libraries\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# read the train and test dataset\n",
        "train_data = pd.read_csv('https://raw.githubusercontent.com/vamsivarma/datasets/master/machine_learning/gbm/train.csv')\n",
        "test_data = pd.read_csv('https://raw.githubusercontent.com/vamsivarma/datasets/master/machine_learning/gbm/test.csv')\n",
        "\n",
        "# shape of the dataset\n",
        "print('Shape of training data :',train_data.shape)\n",
        "print('Shape of testing data :',test_data.shape)\n",
        "\n",
        "# Now, we need to predict the missing target variable in the test data\n",
        "# target variable - Survived\n",
        "\n",
        "# seperate the independent and target variable on training data\n",
        "train_x = train_data.drop(columns=['Survived'],axis=1)\n",
        "train_y = train_data['Survived']\n",
        "\n",
        "# seperate the independent and target variable on testing data\n",
        "test_x = test_data.drop(columns=['Survived'],axis=1)\n",
        "test_y = test_data['Survived']\n",
        "\n",
        "'''\n",
        "Create the object of the GradientBoosting Classifier model\n",
        "You can also add other parameters and test your code here\n",
        "Some parameters are : learning_rate, n_estimators\n",
        "Documentation of sklearn GradientBoosting Classifier: \n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
        "'''\n",
        "model = GradientBoostingClassifier(n_estimators=100,max_depth=5)\n",
        "\n",
        "# fit the model with the training data\n",
        "model.fit(train_x,train_y)\n",
        "\n",
        "# predict the target on the train dataset\n",
        "predict_train = model.predict(train_x)\n",
        "print('\\nTarget on train data',predict_train) \n",
        "\n",
        "# Accuray Score on train dataset\n",
        "accuracy_train = accuracy_score(train_y,predict_train)\n",
        "print('\\naccuracy_score on train dataset : ', accuracy_train)\n",
        "\n",
        "# predict the target on the test dataset\n",
        "predict_test = model.predict(test_x)\n",
        "print('\\nTarget on test data',predict_test) \n",
        "\n",
        "# Accuracy Score on test dataset\n",
        "accuracy_test = accuracy_score(test_y,predict_test)\n",
        "print('\\naccuracy_score on test dataset : ', accuracy_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of training data : (712, 25)\n",
            "Shape of testing data : (179, 25)\n",
            "\n",
            "Target on train data [0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0\n",
            " 1 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0\n",
            " 0 1 1 0 0 1 0 1 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 0\n",
            " 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 1 1 0\n",
            " 0 0 0 1 1 0 0 1 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
            " 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 1 1 1 0 1 0 0 0 1 0\n",
            " 0 1 1 0 1 1 1 0 1 1 0 0 1 0 0 1 1 1 1 0 0 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0\n",
            " 0 0 1 1 0 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1\n",
            " 1 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1\n",
            " 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 0 0 0 1 0 0\n",
            " 0 1 0 0 0 0 0 0 1 0 0 1 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0\n",
            " 0 0 1 1 1 0 0 1 0 1 1 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
            " 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 1\n",
            " 0 0 0 1 1 0 0 1 0 0 1 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 1 1 0\n",
            " 1 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 1 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1\n",
            " 0 0 0 1 0 1 1 1 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 0 1 0 1 0\n",
            " 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0\n",
            " 1 0 1 1 1 0 0 1 0]\n",
            "\n",
            "accuracy_score on train dataset :  0.9550561797752809\n",
            "\n",
            "Target on test data [0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 1 1 0 0 0 1 0 1\n",
            " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0\n",
            " 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 1\n",
            " 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
            " 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 1 1 0 0 0 0 0 0 0]\n",
            "\n",
            "accuracy_score on test dataset :  0.8268156424581006\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6QL2w90HEHm",
        "colab_type": "text"
      },
      "source": [
        "# XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSZovMUPHEUo",
        "colab_type": "code",
        "outputId": "9cc6eea3-2983-4886-cdc1-d3b5a7f7b8f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "'''\n",
        "The following code is for XGBoost\n",
        "Created by - ANALYTICS VIDHYA\n",
        "'''\n",
        "\n",
        "# importing required libraries\n",
        "import pandas as pd\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# read the train and test dataset\n",
        "train_data = pd.read_csv('https://raw.githubusercontent.com/vamsivarma/datasets/master/machine_learning/xgboost/train.csv')\n",
        "test_data = pd.read_csv('https://raw.githubusercontent.com/vamsivarma/datasets/master/machine_learning/xgboost/test.csv')\n",
        "\n",
        "# shape of the dataset\n",
        "print('Shape of training data :',train_data.shape)\n",
        "print('Shape of testing data :',test_data.shape)\n",
        "\n",
        "# Now, we need to predict the missing target variable in the test data\n",
        "# target variable - Survived\n",
        "\n",
        "# seperate the independent and target variable on training data\n",
        "train_x = train_data.drop(columns=['Survived'],axis=1)\n",
        "train_y = train_data['Survived']\n",
        "\n",
        "# seperate the independent and target variable on testing data\n",
        "test_x = test_data.drop(columns=['Survived'],axis=1)\n",
        "test_y = test_data['Survived']\n",
        "\n",
        "'''\n",
        "Create the object of the XGBoost model\n",
        "You can also add other parameters and test your code here\n",
        "Some parameters are : max_depth and n_estimators\n",
        "Documentation of xgboost:\n",
        "\n",
        "https://xgboost.readthedocs.io/en/latest/\n",
        "'''\n",
        "model = XGBClassifier()\n",
        "\n",
        "# fit the model with the training data\n",
        "model.fit(train_x,train_y)\n",
        "\n",
        "\n",
        "# predict the target on the train dataset\n",
        "predict_train = model.predict(train_x)\n",
        "print('\\nTarget on train data',predict_train) \n",
        "\n",
        "# Accuray Score on train dataset\n",
        "accuracy_train = accuracy_score(train_y,predict_train)\n",
        "print('\\naccuracy_score on train dataset : ', accuracy_train)\n",
        "\n",
        "# predict the target on the test dataset\n",
        "predict_test = model.predict(test_x)\n",
        "print('\\nTarget on test data',predict_test) \n",
        "\n",
        "# Accuracy Score on test dataset\n",
        "accuracy_test = accuracy_score(test_y,predict_test)\n",
        "print('\\naccuracy_score on test dataset : ', accuracy_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of training data : (712, 25)\n",
            "Shape of testing data : (179, 25)\n",
            "\n",
            "Target on train data [0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0\n",
            " 1 0 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 0 0 0 1 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0\n",
            " 0 1 1 0 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1\n",
            " 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0\n",
            " 0 0 1 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
            " 0 1 1 1 1 0 0 1 0 1 0 0 0 1 1 1 1 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 1 0 1 0 0 1 1 0\n",
            " 0 1 1 0 1 1 1 0 1 1 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 1 1 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1\n",
            " 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1 1 0 1 0 0 1 1 1\n",
            " 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 1 0 0\n",
            " 0 1 0 0 0 0 0 0 1 0 0 1 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
            " 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1\n",
            " 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 1 1 1 1 1 0 0 0 0 1\n",
            " 0 0 0 1 1 0 0 1 0 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 1 1 0 1 0 0 1 1 0 1 1 1 0\n",
            " 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1\n",
            " 0 0 0 0 0 0 1 1 0 0 1 1 0 0 1 1 1 0 0 0 0 0 1 1 1 0 0 1 0 0 0 1 0 1 0 0 0\n",
            " 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0\n",
            " 1 0 1 1 1 0 0 1 0]\n",
            "\n",
            "accuracy_score on train dataset :  0.8693820224719101\n",
            "\n",
            "Target on test data [0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 1 1 0 1 0 1 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0\n",
            " 1 0 0 0 1 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 1 0 0 1 0 1\n",
            " 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 1 0 1 0 0 0 0 0 0 0\n",
            " 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0]\n",
            "\n",
            "accuracy_score on test dataset :  0.8212290502793296\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}